services:
  cc-vec-bot:
    build:
      context: ..
      dockerfile: docker/Dockerfile.cc-vec-bot
      args:
        PREFETCH_MODEL: ${PREFETCH_MODEL:-1}
        INFERENCE_MODEL: ${INFERENCE_MODEL:-tinyllama}
    image: cc-vec-bot
    environment:
      LLAMA_STACK_PORT: ${LLAMA_STACK_PORT:-5001}
      CHATBOT_PORT: ${CHATBOT_PORT:-8008}
      OLLAMA_PORT: ${OLLAMA_PORT:-11434}
      OLLAMA_STREAMING: ${OLLAMA_STREAMING:-1}
      INFERENCE_MODEL: ${INFERENCE_MODEL:-tinyllama}
    ports:
      - "${LLAMA_STACK_PORT}:${LLAMA_STACK_PORT}"
      - "${CHATBOT_PORT}:${CHATBOT_PORT}"
      - "${OLLAMA_PORT}:${OLLAMA_PORT}"
    volumes:
      - ~/.llama:/root/.llama
    command: ["--port", "${LLAMA_STACK_PORT}"]

